{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-07T13:24:13.977071Z",
     "start_time": "2025-10-07T13:23:18.430973Z"
    }
   },
   "source": [
    "# CUDA 12.1\n",
    "!pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "!pip install torch_geometric\n",
    "!pip install torch-geometric-temporal\n",
    "!pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
    "\n",
    "# Optional dependencies:\n",
    "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
    "!pip install networkx numpy==1.24.3\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torch==2.4.0 in d:\\documents\\notebook\\venv\\lib\\site-packages (2.4.0+cu121)\n",
      "Requirement already satisfied: torchvision==0.19.0 in d:\\documents\\notebook\\venv\\lib\\site-packages (0.19.0+cu121)\n",
      "Requirement already satisfied: torchaudio==2.4.0 in d:\\documents\\notebook\\venv\\lib\\site-packages (2.4.0+cu121)\n",
      "Requirement already satisfied: filelock in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch==2.4.0) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch==2.4.0) (4.15.0)\n",
      "Requirement already satisfied: sympy in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch==2.4.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch==2.4.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch==2.4.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch==2.4.0) (2025.9.0)\n",
      "Collecting numpy (from torchvision==0.19.0)\n",
      "  Downloading https://download.pytorch.org/whl/numpy-2.1.2-cp310-cp310-win_amd64.whl.metadata (59 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\documents\\notebook\\venv\\lib\\site-packages (from torchvision==0.19.0) (11.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\documents\\notebook\\venv\\lib\\site-packages (from jinja2->torch==2.4.0) (3.0.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\documents\\notebook\\venv\\lib\\site-packages (from sympy->torch==2.4.0) (1.3.0)\n",
      "Downloading https://download.pytorch.org/whl/numpy-2.1.2-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/12.9 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 4.5/12.9 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.2/12.9 MB 14.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 15.8 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-2.1.2\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torch_geometric in d:\\documents\\notebook\\venv\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: aiohttp in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch_geometric) (3.13.0)\n",
      "Requirement already satisfied: fsspec in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch_geometric) (2025.9.0)\n",
      "Requirement already satisfied: jinja2 in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch_geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch_geometric) (2.1.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch_geometric) (7.1.0)\n",
      "Requirement already satisfied: pyparsing in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch_geometric) (3.2.5)\n",
      "Requirement already satisfied: requests in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch_geometric) (2.32.5)\n",
      "Requirement already satisfied: tqdm in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch_geometric) (4.67.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in d:\\documents\\notebook\\venv\\lib\\site-packages (from aiohttp->torch_geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in d:\\documents\\notebook\\venv\\lib\\site-packages (from aiohttp->torch_geometric) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in d:\\documents\\notebook\\venv\\lib\\site-packages (from aiohttp->torch_geometric) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\documents\\notebook\\venv\\lib\\site-packages (from aiohttp->torch_geometric) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\documents\\notebook\\venv\\lib\\site-packages (from aiohttp->torch_geometric) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\documents\\notebook\\venv\\lib\\site-packages (from aiohttp->torch_geometric) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\documents\\notebook\\venv\\lib\\site-packages (from aiohttp->torch_geometric) (0.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\documents\\notebook\\venv\\lib\\site-packages (from aiohttp->torch_geometric) (1.22.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\documents\\notebook\\venv\\lib\\site-packages (from jinja2->torch_geometric) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\documents\\notebook\\venv\\lib\\site-packages (from requests->torch_geometric) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\documents\\notebook\\venv\\lib\\site-packages (from requests->torch_geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\documents\\notebook\\venv\\lib\\site-packages (from requests->torch_geometric) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\documents\\notebook\\venv\\lib\\site-packages (from requests->torch_geometric) (2025.10.5)\n",
      "Requirement already satisfied: colorama in d:\\documents\\notebook\\venv\\lib\\site-packages (from tqdm->torch_geometric) (0.4.6)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in d:\\documents\\notebook\\venv\\lib\\site-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: torch-geometric-temporal in d:\\documents\\notebook\\venv\\lib\\site-packages (0.56.2)\n",
      "Requirement already satisfied: decorator==4.4.2 in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch-geometric-temporal) (4.4.2)\n",
      "Requirement already satisfied: torch in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch-geometric-temporal) (2.4.0+cu121)\n",
      "Requirement already satisfied: cython in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch-geometric-temporal) (3.1.4)\n",
      "Requirement already satisfied: torch-sparse in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch-geometric-temporal) (0.6.18+pt24cu121)\n",
      "Requirement already satisfied: torch-scatter in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch-geometric-temporal) (2.1.2+pt24cu121)\n",
      "Requirement already satisfied: torch-geometric in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch-geometric-temporal) (2.6.1)\n",
      "Requirement already satisfied: numpy in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch-geometric-temporal) (2.1.2)\n",
      "Requirement already satisfied: networkx in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch-geometric-temporal) (3.4.2)\n",
      "Requirement already satisfied: filelock in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch->torch-geometric-temporal) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch->torch-geometric-temporal) (4.15.0)\n",
      "Requirement already satisfied: sympy in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch->torch-geometric-temporal) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch->torch-geometric-temporal) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch->torch-geometric-temporal) (2025.9.0)\n",
      "Requirement already satisfied: aiohttp in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch-geometric->torch-geometric-temporal) (3.13.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch-geometric->torch-geometric-temporal) (7.1.0)\n",
      "Requirement already satisfied: pyparsing in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch-geometric->torch-geometric-temporal) (3.2.5)\n",
      "Requirement already satisfied: requests in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch-geometric->torch-geometric-temporal) (2.32.5)\n",
      "Requirement already satisfied: tqdm in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch-geometric->torch-geometric-temporal) (4.67.1)\n",
      "Requirement already satisfied: scipy in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch-sparse->torch-geometric-temporal) (1.15.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in d:\\documents\\notebook\\venv\\lib\\site-packages (from aiohttp->torch-geometric->torch-geometric-temporal) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in d:\\documents\\notebook\\venv\\lib\\site-packages (from aiohttp->torch-geometric->torch-geometric-temporal) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in d:\\documents\\notebook\\venv\\lib\\site-packages (from aiohttp->torch-geometric->torch-geometric-temporal) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\documents\\notebook\\venv\\lib\\site-packages (from aiohttp->torch-geometric->torch-geometric-temporal) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\documents\\notebook\\venv\\lib\\site-packages (from aiohttp->torch-geometric->torch-geometric-temporal) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\documents\\notebook\\venv\\lib\\site-packages (from aiohttp->torch-geometric->torch-geometric-temporal) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\documents\\notebook\\venv\\lib\\site-packages (from aiohttp->torch-geometric->torch-geometric-temporal) (0.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\documents\\notebook\\venv\\lib\\site-packages (from aiohttp->torch-geometric->torch-geometric-temporal) (1.22.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\documents\\notebook\\venv\\lib\\site-packages (from jinja2->torch->torch-geometric-temporal) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\documents\\notebook\\venv\\lib\\site-packages (from requests->torch-geometric->torch-geometric-temporal) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\documents\\notebook\\venv\\lib\\site-packages (from requests->torch-geometric->torch-geometric-temporal) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\documents\\notebook\\venv\\lib\\site-packages (from requests->torch-geometric->torch-geometric-temporal) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\documents\\notebook\\venv\\lib\\site-packages (from requests->torch-geometric->torch-geometric-temporal) (2025.10.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\documents\\notebook\\venv\\lib\\site-packages (from sympy->torch->torch-geometric-temporal) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\documents\\notebook\\venv\\lib\\site-packages (from tqdm->torch-geometric->torch-geometric-temporal) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple, https://pypi.ngc.nvidia.com\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
      "Requirement already satisfied: torch-scatter in d:\\documents\\notebook\\venv\\lib\\site-packages (2.1.2+pt24cu121)\n",
      "Requirement already satisfied: torch-sparse in d:\\documents\\notebook\\venv\\lib\\site-packages (0.6.18+pt24cu121)\n",
      "Requirement already satisfied: scipy in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch-sparse) (1.15.3)\n",
      "Requirement already satisfied: numpy<2.5,>=1.23.5 in d:\\documents\\notebook\\venv\\lib\\site-packages (from scipy->torch-sparse) (2.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple, https://pypi.ngc.nvidia.com\n",
      "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
      "Requirement already satisfied: pyg_lib in d:\\documents\\notebook\\venv\\lib\\site-packages (0.4.0+pt24cu121)\n",
      "Requirement already satisfied: torch_scatter in d:\\documents\\notebook\\venv\\lib\\site-packages (2.1.2+pt24cu121)\n",
      "Requirement already satisfied: torch_sparse in d:\\documents\\notebook\\venv\\lib\\site-packages (0.6.18+pt24cu121)\n",
      "Requirement already satisfied: torch_cluster in d:\\documents\\notebook\\venv\\lib\\site-packages (1.6.3+pt24cu121)\n",
      "Requirement already satisfied: torch_spline_conv in d:\\documents\\notebook\\venv\\lib\\site-packages (1.2.2+pt24cu121)\n",
      "Requirement already satisfied: scipy in d:\\documents\\notebook\\venv\\lib\\site-packages (from torch_sparse) (1.15.3)\n",
      "Collecting numpy<2.5,>=1.23.5 (from scipy->torch_sparse)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a3/dd/4b822569d6b96c39d1215dbae0582fd99954dcbcf0c1a13c61783feaca3f/numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "     ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "     ----- ---------------------------------- 1.8/12.9 MB 8.4 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.5/12.9 MB 13.4 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 8.4/12.9 MB 14.4 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 12.1/12.9 MB 14.2 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.9/12.9 MB 14.7 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-2.2.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: networkx in d:\\documents\\notebook\\venv\\lib\\site-packages (3.4.2)\n",
      "Collecting numpy==1.24.3\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/65/5d/46da284b0bf6cfbf04082c3c5e84399664d69e41c11a33587ad49b0c64e5/numpy-1.24.3-cp310-cp310-win_amd64.whl (14.8 MB)\n",
      "     ---------------------------------------- 0.0/14.8 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 1.8/14.8 MB 8.4 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 5.5/14.8 MB 12.9 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 8.4/14.8 MB 14.1 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 12.1/14.8 MB 14.5 MB/s eta 0:00:01\n",
      "     --------------------------------------- 14.8/14.8 MB 15.0 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "Successfully installed numpy-1.24.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T14:06:26.158629Z",
     "start_time": "2025-10-07T14:06:17.673490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric_temporal.nn.recurrent import GConvGRU\n",
    "from torch_geometric_temporal.signal import DynamicGraphTemporalSignal\n",
    "\n",
    "# reproducible\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "def generate_dynamic_graph(num_nodes=10, num_timesteps=8):\n",
    "    edge_indices, edge_weights, features, targets = [], [], [], []\n",
    "    for t in range(num_timesteps):\n",
    "        g = nx.erdos_renyi_graph(num_nodes, p=0.4, seed=t)\n",
    "        g.add_nodes_from(range(num_nodes))  # ensure nodes 0..num_nodes-1\n",
    "\n",
    "        edges = list(g.edges())\n",
    "        if len(edges) == 0:\n",
    "            edge_index = np.empty((2, 0), dtype=np.int64)\n",
    "            edge_attr = np.empty((0, 2), dtype=np.float32)\n",
    "        else:\n",
    "            edge_index = np.array(edges, dtype=np.int64).T  # shape (2, E)\n",
    "            edge_attr = np.random.rand(edge_index.shape[1], 2).astype(np.float32)\n",
    "\n",
    "        x = np.random.rand(num_nodes, 3).astype(np.float32)\n",
    "        y = (edge_attr.sum(axis=1) > 1.0).astype(np.int64) if edge_attr.shape[0] > 0 else np.empty((0,), dtype=np.int64)\n",
    "        w = edge_attr[:, 0].astype(np.float32) if edge_attr.shape[0] > 0 else np.empty((0,), dtype=np.float32)\n",
    "\n",
    "        edge_indices.append(edge_index)\n",
    "        edge_weights.append(w)\n",
    "        features.append(x)\n",
    "        targets.append(y)\n",
    "\n",
    "    return DynamicGraphTemporalSignal(edge_indices, edge_weights, features, targets)\n",
    "\n",
    "\n",
    "# create dataset\n",
    "num_nodes = 10\n",
    "dataset = generate_dynamic_graph(num_nodes=num_nodes, num_timesteps=8)\n",
    "print(\"Snapshots:\", dataset.snapshot_count)\n",
    "\n",
    "# model\n",
    "class RecurrentLinkClassifier(torch.nn.Module):\n",
    "    def __init__(self, node_features, hidden_dim, num_nodes):\n",
    "        super().__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.recurrent = GConvGRU(node_features, hidden_dim, K=2)\n",
    "        self.fc = torch.nn.Linear(hidden_dim * 2, 2)\n",
    "\n",
    "    def forward(self, x, edge_index, h=None):\n",
    "        # ensure h has correct shape [num_nodes, hidden_dim]\n",
    "        if h is None or h.size(0) != self.num_nodes:\n",
    "            h = torch.zeros(self.num_nodes, self.recurrent.out_channels, device=x.device)\n",
    "        # IMPORTANT: pass hidden state as keyword H=h (NOT as third positional argument)\n",
    "        h = self.recurrent(x, edge_index, edge_weight=None, H=h)\n",
    "        return h\n",
    "\n",
    "    def predict_links(self, h, edge_index):\n",
    "        src, dst = edge_index\n",
    "        # safety check\n",
    "        if src.max() >= h.size(0) or dst.max() >= h.size(0):\n",
    "            raise ValueError(f\"edge_index out of range: node count={h.size(0)}, max src={src.max()}, max dst={dst.max()}\")\n",
    "        z = torch.cat([h[src], h[dst]], dim=1)\n",
    "        return self.fc(z)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = RecurrentLinkClassifier(node_features=3, hidden_dim=16, num_nodes=num_nodes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def to_tensor(data, dtype=torch.float32):\n",
    "    if isinstance(data, np.ndarray):\n",
    "        return torch.from_numpy(data).to(dtype=dtype, device=device)\n",
    "    elif isinstance(data, torch.Tensor):\n",
    "        return data.to(dtype=dtype, device=device)\n",
    "    else:\n",
    "        raise TypeError(f\"Unexpected data type: {type(data)}\")\n",
    "\n",
    "# training\n",
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1:02d}/{epochs}\")\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    h = None\n",
    "    for snapshot in dataset:\n",
    "        x = to_tensor(snapshot.x, torch.float32)               # [num_nodes, feat]\n",
    "        edge_index = to_tensor(snapshot.edge_index, torch.long)  # [2, E]\n",
    "        if edge_index.shape[1] == 0:\n",
    "            continue\n",
    "        # snapshot.y is 1D array of length E\n",
    "        y_np = snapshot.y\n",
    "        y = torch.from_numpy(y_np).long().to(device) if isinstance(y_np, np.ndarray) else y_np.long().to(device)\n",
    "\n",
    "        # FORWARD - pass H as keyword to avoid being misinterpreted as edge_weight\n",
    "        h = model(x, edge_index, h)\n",
    "        h = h.detach()\n",
    "        preds = model.predict_links(h, edge_index)  # [E, 2]\n",
    "\n",
    "        loss = criterion(preds, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss.item())\n",
    "\n",
    "    print(f\"Epoch {epoch+1:02d} | Loss: {total_loss:.4f}\")\n",
    "\n",
    "# evaluation\n",
    "model.eval()\n",
    "h = None\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for snapshot in dataset:\n",
    "        x = to_tensor(snapshot.x, torch.float32)\n",
    "        edge_index = to_tensor(snapshot.edge_index, torch.long)\n",
    "        if edge_index.shape[1] == 0:\n",
    "            continue\n",
    "        y_np = snapshot.y\n",
    "        y = torch.from_numpy(y_np).long().to(device) if isinstance(y_np, np.ndarray) else y_np.long().to(device)\n",
    "\n",
    "        h = model(x, edge_index, h)\n",
    "        preds = model.predict_links(h, edge_index)\n",
    "        pred_labels = preds.argmax(dim=1)\n",
    "        correct += (pred_labels == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "if total > 0:\n",
    "    print(f\"Accuracy: {correct/total:.4f} ({correct}/{total})\")\n",
    "else:\n",
    "    print(\"No edges to evaluate.\")\n"
   ],
   "id": "7eb4d2376e7e1e83",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshots: 8\n",
      "Epoch 01/200\n",
      "Epoch 01 | Loss: 5.7364\n",
      "Epoch 02/200\n",
      "Epoch 02 | Loss: 5.5187\n",
      "Epoch 03/200\n",
      "Epoch 03 | Loss: 5.5395\n",
      "Epoch 04/200\n",
      "Epoch 04 | Loss: 5.4838\n",
      "Epoch 05/200\n",
      "Epoch 05 | Loss: 5.4420\n",
      "Epoch 06/200\n",
      "Epoch 06 | Loss: 5.4163\n",
      "Epoch 07/200\n",
      "Epoch 07 | Loss: 5.4041\n",
      "Epoch 08/200\n",
      "Epoch 08 | Loss: 5.3886\n",
      "Epoch 09/200\n",
      "Epoch 09 | Loss: 5.3730\n",
      "Epoch 10/200\n",
      "Epoch 10 | Loss: 5.3593\n",
      "Epoch 11/200\n",
      "Epoch 11 | Loss: 5.3477\n",
      "Epoch 12/200\n",
      "Epoch 12 | Loss: 5.3368\n",
      "Epoch 13/200\n",
      "Epoch 13 | Loss: 5.3263\n",
      "Epoch 14/200\n",
      "Epoch 14 | Loss: 5.3164\n",
      "Epoch 15/200\n",
      "Epoch 15 | Loss: 5.3071\n",
      "Epoch 16/200\n",
      "Epoch 16 | Loss: 5.2983\n",
      "Epoch 17/200\n",
      "Epoch 17 | Loss: 5.2899\n",
      "Epoch 18/200\n",
      "Epoch 18 | Loss: 5.2818\n",
      "Epoch 19/200\n",
      "Epoch 19 | Loss: 5.2740\n",
      "Epoch 20/200\n",
      "Epoch 20 | Loss: 5.2665\n",
      "Epoch 21/200\n",
      "Epoch 21 | Loss: 5.2592\n",
      "Epoch 22/200\n",
      "Epoch 22 | Loss: 5.2521\n",
      "Epoch 23/200\n",
      "Epoch 23 | Loss: 5.2453\n",
      "Epoch 24/200\n",
      "Epoch 24 | Loss: 5.2386\n",
      "Epoch 25/200\n",
      "Epoch 25 | Loss: 5.2320\n",
      "Epoch 26/200\n",
      "Epoch 26 | Loss: 5.2257\n",
      "Epoch 27/200\n",
      "Epoch 27 | Loss: 5.2194\n",
      "Epoch 28/200\n",
      "Epoch 28 | Loss: 5.2133\n",
      "Epoch 29/200\n",
      "Epoch 29 | Loss: 5.2073\n",
      "Epoch 30/200\n",
      "Epoch 30 | Loss: 5.2014\n",
      "Epoch 31/200\n",
      "Epoch 31 | Loss: 5.1955\n",
      "Epoch 32/200\n",
      "Epoch 32 | Loss: 5.1898\n",
      "Epoch 33/200\n",
      "Epoch 33 | Loss: 5.1842\n",
      "Epoch 34/200\n",
      "Epoch 34 | Loss: 5.1787\n",
      "Epoch 35/200\n",
      "Epoch 35 | Loss: 5.1732\n",
      "Epoch 36/200\n",
      "Epoch 36 | Loss: 5.1678\n",
      "Epoch 37/200\n",
      "Epoch 37 | Loss: 5.1625\n",
      "Epoch 38/200\n",
      "Epoch 38 | Loss: 5.1573\n",
      "Epoch 39/200\n",
      "Epoch 39 | Loss: 5.1522\n",
      "Epoch 40/200\n",
      "Epoch 40 | Loss: 5.1471\n",
      "Epoch 41/200\n",
      "Epoch 41 | Loss: 5.1420\n",
      "Epoch 42/200\n",
      "Epoch 42 | Loss: 5.1370\n",
      "Epoch 43/200\n",
      "Epoch 43 | Loss: 5.1321\n",
      "Epoch 44/200\n",
      "Epoch 44 | Loss: 5.1273\n",
      "Epoch 45/200\n",
      "Epoch 45 | Loss: 5.1225\n",
      "Epoch 46/200\n",
      "Epoch 46 | Loss: 5.1177\n",
      "Epoch 47/200\n",
      "Epoch 47 | Loss: 5.1130\n",
      "Epoch 48/200\n",
      "Epoch 48 | Loss: 5.1084\n",
      "Epoch 49/200\n",
      "Epoch 49 | Loss: 5.1038\n",
      "Epoch 50/200\n",
      "Epoch 50 | Loss: 5.0993\n",
      "Epoch 51/200\n",
      "Epoch 51 | Loss: 5.0948\n",
      "Epoch 52/200\n",
      "Epoch 52 | Loss: 5.0903\n",
      "Epoch 53/200\n",
      "Epoch 53 | Loss: 5.0859\n",
      "Epoch 54/200\n",
      "Epoch 54 | Loss: 5.0816\n",
      "Epoch 55/200\n",
      "Epoch 55 | Loss: 5.0772\n",
      "Epoch 56/200\n",
      "Epoch 56 | Loss: 5.0730\n",
      "Epoch 57/200\n",
      "Epoch 57 | Loss: 5.0687\n",
      "Epoch 58/200\n",
      "Epoch 58 | Loss: 5.0645\n",
      "Epoch 59/200\n",
      "Epoch 59 | Loss: 5.0604\n",
      "Epoch 60/200\n",
      "Epoch 60 | Loss: 5.0563\n",
      "Epoch 61/200\n",
      "Epoch 61 | Loss: 5.0522\n",
      "Epoch 62/200\n",
      "Epoch 62 | Loss: 5.0481\n",
      "Epoch 63/200\n",
      "Epoch 63 | Loss: 5.0441\n",
      "Epoch 64/200\n",
      "Epoch 64 | Loss: 5.0402\n",
      "Epoch 65/200\n",
      "Epoch 65 | Loss: 5.0362\n",
      "Epoch 66/200\n",
      "Epoch 66 | Loss: 5.0323\n",
      "Epoch 67/200\n",
      "Epoch 67 | Loss: 5.0285\n",
      "Epoch 68/200\n",
      "Epoch 68 | Loss: 5.0246\n",
      "Epoch 69/200\n",
      "Epoch 69 | Loss: 5.0208\n",
      "Epoch 70/200\n",
      "Epoch 70 | Loss: 5.0171\n",
      "Epoch 71/200\n",
      "Epoch 71 | Loss: 5.0133\n",
      "Epoch 72/200\n",
      "Epoch 72 | Loss: 5.0096\n",
      "Epoch 73/200\n",
      "Epoch 73 | Loss: 5.0060\n",
      "Epoch 74/200\n",
      "Epoch 74 | Loss: 5.0023\n",
      "Epoch 75/200\n",
      "Epoch 75 | Loss: 4.9987\n",
      "Epoch 76/200\n",
      "Epoch 76 | Loss: 4.9951\n",
      "Epoch 77/200\n",
      "Epoch 77 | Loss: 4.9916\n",
      "Epoch 78/200\n",
      "Epoch 78 | Loss: 4.9880\n",
      "Epoch 79/200\n",
      "Epoch 79 | Loss: 4.9845\n",
      "Epoch 80/200\n",
      "Epoch 80 | Loss: 4.9811\n",
      "Epoch 81/200\n",
      "Epoch 81 | Loss: 4.9776\n",
      "Epoch 82/200\n",
      "Epoch 82 | Loss: 4.9742\n",
      "Epoch 83/200\n",
      "Epoch 83 | Loss: 4.9708\n",
      "Epoch 84/200\n",
      "Epoch 84 | Loss: 4.9674\n",
      "Epoch 85/200\n",
      "Epoch 85 | Loss: 4.9641\n",
      "Epoch 86/200\n",
      "Epoch 86 | Loss: 4.9607\n",
      "Epoch 87/200\n",
      "Epoch 87 | Loss: 4.9575\n",
      "Epoch 88/200\n",
      "Epoch 88 | Loss: 4.9542\n",
      "Epoch 89/200\n",
      "Epoch 89 | Loss: 4.9509\n",
      "Epoch 90/200\n",
      "Epoch 90 | Loss: 4.9477\n",
      "Epoch 91/200\n",
      "Epoch 91 | Loss: 4.9445\n",
      "Epoch 92/200\n",
      "Epoch 92 | Loss: 4.9413\n",
      "Epoch 93/200\n",
      "Epoch 93 | Loss: 4.9382\n",
      "Epoch 94/200\n",
      "Epoch 94 | Loss: 4.9350\n",
      "Epoch 95/200\n",
      "Epoch 95 | Loss: 4.9319\n",
      "Epoch 96/200\n",
      "Epoch 96 | Loss: 4.9288\n",
      "Epoch 97/200\n",
      "Epoch 97 | Loss: 4.9258\n",
      "Epoch 98/200\n",
      "Epoch 98 | Loss: 4.9227\n",
      "Epoch 99/200\n",
      "Epoch 99 | Loss: 4.9197\n",
      "Epoch 100/200\n",
      "Epoch 100 | Loss: 4.9167\n",
      "Epoch 101/200\n",
      "Epoch 101 | Loss: 4.9137\n",
      "Epoch 102/200\n",
      "Epoch 102 | Loss: 4.9107\n",
      "Epoch 103/200\n",
      "Epoch 103 | Loss: 4.9078\n",
      "Epoch 104/200\n",
      "Epoch 104 | Loss: 4.9049\n",
      "Epoch 105/200\n",
      "Epoch 105 | Loss: 4.9020\n",
      "Epoch 106/200\n",
      "Epoch 106 | Loss: 4.8991\n",
      "Epoch 107/200\n",
      "Epoch 107 | Loss: 4.8962\n",
      "Epoch 108/200\n",
      "Epoch 108 | Loss: 4.8934\n",
      "Epoch 109/200\n",
      "Epoch 109 | Loss: 4.8905\n",
      "Epoch 110/200\n",
      "Epoch 110 | Loss: 4.8877\n",
      "Epoch 111/200\n",
      "Epoch 111 | Loss: 4.8849\n",
      "Epoch 112/200\n",
      "Epoch 112 | Loss: 4.8822\n",
      "Epoch 113/200\n",
      "Epoch 113 | Loss: 4.8794\n",
      "Epoch 114/200\n",
      "Epoch 114 | Loss: 4.8767\n",
      "Epoch 115/200\n",
      "Epoch 115 | Loss: 4.8739\n",
      "Epoch 116/200\n",
      "Epoch 116 | Loss: 4.8712\n",
      "Epoch 117/200\n",
      "Epoch 117 | Loss: 4.8686\n",
      "Epoch 118/200\n",
      "Epoch 118 | Loss: 4.8659\n",
      "Epoch 119/200\n",
      "Epoch 119 | Loss: 4.8632\n",
      "Epoch 120/200\n",
      "Epoch 120 | Loss: 4.8606\n",
      "Epoch 121/200\n",
      "Epoch 121 | Loss: 4.8580\n",
      "Epoch 122/200\n",
      "Epoch 122 | Loss: 4.8554\n",
      "Epoch 123/200\n",
      "Epoch 123 | Loss: 4.8528\n",
      "Epoch 124/200\n",
      "Epoch 124 | Loss: 4.8502\n",
      "Epoch 125/200\n",
      "Epoch 125 | Loss: 4.8477\n",
      "Epoch 126/200\n",
      "Epoch 126 | Loss: 4.8451\n",
      "Epoch 127/200\n",
      "Epoch 127 | Loss: 4.8426\n",
      "Epoch 128/200\n",
      "Epoch 128 | Loss: 4.8401\n",
      "Epoch 129/200\n",
      "Epoch 129 | Loss: 4.8376\n",
      "Epoch 130/200\n",
      "Epoch 130 | Loss: 4.8351\n",
      "Epoch 131/200\n",
      "Epoch 131 | Loss: 4.8326\n",
      "Epoch 132/200\n",
      "Epoch 132 | Loss: 4.8302\n",
      "Epoch 133/200\n",
      "Epoch 133 | Loss: 4.8277\n",
      "Epoch 134/200\n",
      "Epoch 134 | Loss: 4.8253\n",
      "Epoch 135/200\n",
      "Epoch 135 | Loss: 4.8229\n",
      "Epoch 136/200\n",
      "Epoch 136 | Loss: 4.8205\n",
      "Epoch 137/200\n",
      "Epoch 137 | Loss: 4.8181\n",
      "Epoch 138/200\n",
      "Epoch 138 | Loss: 4.8158\n",
      "Epoch 139/200\n",
      "Epoch 139 | Loss: 4.8134\n",
      "Epoch 140/200\n",
      "Epoch 140 | Loss: 4.8111\n",
      "Epoch 141/200\n",
      "Epoch 141 | Loss: 4.8088\n",
      "Epoch 142/200\n",
      "Epoch 142 | Loss: 4.8065\n",
      "Epoch 143/200\n",
      "Epoch 143 | Loss: 4.8042\n",
      "Epoch 144/200\n",
      "Epoch 144 | Loss: 4.8019\n",
      "Epoch 145/200\n",
      "Epoch 145 | Loss: 4.7996\n",
      "Epoch 146/200\n",
      "Epoch 146 | Loss: 4.7973\n",
      "Epoch 147/200\n",
      "Epoch 147 | Loss: 4.7951\n",
      "Epoch 148/200\n",
      "Epoch 148 | Loss: 4.7929\n",
      "Epoch 149/200\n",
      "Epoch 149 | Loss: 4.7907\n",
      "Epoch 150/200\n",
      "Epoch 150 | Loss: 4.7884\n",
      "Epoch 151/200\n",
      "Epoch 151 | Loss: 4.7862\n",
      "Epoch 152/200\n",
      "Epoch 152 | Loss: 4.7841\n",
      "Epoch 153/200\n",
      "Epoch 153 | Loss: 4.7819\n",
      "Epoch 154/200\n",
      "Epoch 154 | Loss: 4.7797\n",
      "Epoch 155/200\n",
      "Epoch 155 | Loss: 4.7776\n",
      "Epoch 156/200\n",
      "Epoch 156 | Loss: 4.7755\n",
      "Epoch 157/200\n",
      "Epoch 157 | Loss: 4.7733\n",
      "Epoch 158/200\n",
      "Epoch 158 | Loss: 4.7712\n",
      "Epoch 159/200\n",
      "Epoch 159 | Loss: 4.7691\n",
      "Epoch 160/200\n",
      "Epoch 160 | Loss: 4.7670\n",
      "Epoch 161/200\n",
      "Epoch 161 | Loss: 4.7650\n",
      "Epoch 162/200\n",
      "Epoch 162 | Loss: 4.7629\n",
      "Epoch 163/200\n",
      "Epoch 163 | Loss: 4.7608\n",
      "Epoch 164/200\n",
      "Epoch 164 | Loss: 4.7588\n",
      "Epoch 165/200\n",
      "Epoch 165 | Loss: 4.7568\n",
      "Epoch 166/200\n",
      "Epoch 166 | Loss: 4.7547\n",
      "Epoch 167/200\n",
      "Epoch 167 | Loss: 4.7527\n",
      "Epoch 168/200\n",
      "Epoch 168 | Loss: 4.7507\n",
      "Epoch 169/200\n",
      "Epoch 169 | Loss: 4.7487\n",
      "Epoch 170/200\n",
      "Epoch 170 | Loss: 4.7468\n",
      "Epoch 171/200\n",
      "Epoch 171 | Loss: 4.7448\n",
      "Epoch 172/200\n",
      "Epoch 172 | Loss: 4.7428\n",
      "Epoch 173/200\n",
      "Epoch 173 | Loss: 4.7409\n",
      "Epoch 174/200\n",
      "Epoch 174 | Loss: 4.7389\n",
      "Epoch 175/200\n",
      "Epoch 175 | Loss: 4.7370\n",
      "Epoch 176/200\n",
      "Epoch 176 | Loss: 4.7351\n",
      "Epoch 177/200\n",
      "Epoch 177 | Loss: 4.7332\n",
      "Epoch 178/200\n",
      "Epoch 178 | Loss: 4.7313\n",
      "Epoch 179/200\n",
      "Epoch 179 | Loss: 4.7294\n",
      "Epoch 180/200\n",
      "Epoch 180 | Loss: 4.7275\n",
      "Epoch 181/200\n",
      "Epoch 181 | Loss: 4.7256\n",
      "Epoch 182/200\n",
      "Epoch 182 | Loss: 4.7238\n",
      "Epoch 183/200\n",
      "Epoch 183 | Loss: 4.7219\n",
      "Epoch 184/200\n",
      "Epoch 184 | Loss: 4.7201\n",
      "Epoch 185/200\n",
      "Epoch 185 | Loss: 4.7183\n",
      "Epoch 186/200\n",
      "Epoch 186 | Loss: 4.7164\n",
      "Epoch 187/200\n",
      "Epoch 187 | Loss: 4.7146\n",
      "Epoch 188/200\n",
      "Epoch 188 | Loss: 4.7128\n",
      "Epoch 189/200\n",
      "Epoch 189 | Loss: 4.7110\n",
      "Epoch 190/200\n",
      "Epoch 190 | Loss: 4.7092\n",
      "Epoch 191/200\n",
      "Epoch 191 | Loss: 4.7075\n",
      "Epoch 192/200\n",
      "Epoch 192 | Loss: 4.7057\n",
      "Epoch 193/200\n",
      "Epoch 193 | Loss: 4.7039\n",
      "Epoch 194/200\n",
      "Epoch 194 | Loss: 4.7022\n",
      "Epoch 195/200\n",
      "Epoch 195 | Loss: 4.7005\n",
      "Epoch 196/200\n",
      "Epoch 196 | Loss: 4.6987\n",
      "Epoch 197/200\n",
      "Epoch 197 | Loss: 4.6970\n",
      "Epoch 198/200\n",
      "Epoch 198 | Loss: 4.6953\n",
      "Epoch 199/200\n",
      "Epoch 199 | Loss: 4.6936\n",
      "Epoch 200/200\n",
      "Epoch 200 | Loss: 4.6919\n",
      "Accuracy: 0.6765 (92/136)\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
